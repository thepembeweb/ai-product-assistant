{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07b40f5",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c89904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Prefetch, Filter, FieldCondition, MatchText, FusionQuery, Document\n",
    "\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Send, Command\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional, Sequence\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json\n",
    "\n",
    "from utils.utils import get_tool_descriptions, format_ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model,\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358067d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(query, qdrant_client, k=5):\n",
    "\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"Amazon-items-collection-01-hybrid-search\",\n",
    "        prefetch=[\n",
    "            Prefetch(\n",
    "                query=query_embedding,\n",
    "                using=\"text-embedding-3-small\",\n",
    "                limit=20\n",
    "            ),\n",
    "            Prefetch(\n",
    "                query=Document(\n",
    "                    text=query,\n",
    "                    model=\"qdrant/bm25\"\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=20\n",
    "            )\n",
    "        ],\n",
    "        query=FusionQuery(fusion=\"rrf\"),\n",
    "        limit=k,\n",
    "    )\n",
    "\n",
    "    retrieved_context_ids = []\n",
    "    retrieved_context = []\n",
    "    similarity_scores = []\n",
    "    retrieved_context_ratings = []\n",
    "\n",
    "    for result in results.points:\n",
    "        retrieved_context_ids.append(result.payload[\"parent_asin\"])\n",
    "        retrieved_context.append(result.payload[\"description\"])\n",
    "        retrieved_context_ratings.append(result.payload[\"average_rating\"])\n",
    "        similarity_scores.append(result.score)\n",
    "\n",
    "    return {\n",
    "        \"retrieved_context_ids\": retrieved_context_ids,\n",
    "        \"retrieved_context\": retrieved_context,\n",
    "        \"retrieved_context_ratings\": retrieved_context_ratings,\n",
    "        \"similarity_scores\": similarity_scores,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can I get a tablet?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd7b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = retrieve_data(query, qdrant_client, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62456150",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4afb66",
   "metadata": {},
   "source": [
    "### Multi-Intent Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can I get a tablet for my kid, a watch for me and a laptop for my wife?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54809851",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = retrieve_data(query, qdrant_client, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada80849",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpandResponse(BaseModel):\n",
    "   statements: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expand_node(query) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are part of a shopping assistant that can answer questions about products in stock.\n",
    "\n",
    "Instructions:\n",
    "- You will be given a question and you need to expand it into a list of statements that can be used in contextual search to retrieve relevant products.\n",
    "- The statements should not overlap in context.\n",
    "\n",
    "<Question>\n",
    "{{ query }}\n",
    "</Question>\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      query=query\n",
    "   )\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        response_model=QueryExpandResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   return {\n",
    "      \"queries\": response.statements\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39096c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = query_expand_node(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d598afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6228b",
   "metadata": {},
   "source": [
    "### LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebef9929",
   "metadata": {},
   "source": [
    "#### Query Expansion (Sequential Execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    expanded_query: List[str] = []\n",
    "    retrieved_context: Annotated[List[str], add] = []\n",
    "    initial_query: str = \"\"\n",
    "    answer: str = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d0ad4",
   "metadata": {},
   "source": [
    "#### Query Expansion / Rewriting Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccaadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpandResponse(BaseModel):\n",
    "   expanded_query: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"query_expand_node\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1-mini\"}\n",
    ")\n",
    "def query_expand_node(state: State) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are part of a shopping assistant that can answer questions about products in stock.\n",
    "\n",
    "Instructions:\n",
    "- You will be given a question and you need to expand it into a list of statements that can be used in contextual search to retrieve relevant products.\n",
    "- The statements should not overlap in context.\n",
    "- Be as concise as possible, do not make up synonims for statements, one statement per piece of context.\n",
    "\n",
    "<Question>\n",
    "{{ query }}\n",
    "</Question>\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      query=state.initial_query\n",
    "   )\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        response_model=QueryExpandResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   return {\n",
    "      \"expanded_query\": response.expanded_query\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5af62",
   "metadata": {},
   "source": [
    "#### Retriever Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"embed_query\",\n",
    "    run_type=\"embedding\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"text-embedding-3-small\"}\n",
    ")\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model,\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "@traceable(\n",
    "    name=\"retrieve_top_n\",\n",
    "    run_type=\"retriever\"\n",
    ")\n",
    "def retrieve_data(query, k=5):\n",
    "\n",
    "    qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"Amazon-items-collection-01-hybrid-search\",\n",
    "        prefetch=[\n",
    "            Prefetch(\n",
    "                query=query_embedding,\n",
    "                using=\"text-embedding-3-small\",\n",
    "                limit=20\n",
    "            ),\n",
    "            Prefetch(\n",
    "                query=Document(\n",
    "                    text=query,\n",
    "                    model=\"qdrant/bm25\"\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=20\n",
    "            )\n",
    "        ],\n",
    "        query=FusionQuery(fusion=\"rrf\"),\n",
    "        limit=k,\n",
    "    )\n",
    "\n",
    "    retrieved_context_ids = []\n",
    "    retrieved_context = []\n",
    "    similarity_scores = []\n",
    "    retrieved_context_ratings = []\n",
    "\n",
    "    for result in results.points:\n",
    "        retrieved_context_ids.append(result.payload[\"parent_asin\"])\n",
    "        retrieved_context.append(result.payload[\"description\"])\n",
    "        retrieved_context_ratings.append(result.payload[\"average_rating\"])\n",
    "        similarity_scores.append(result.score)\n",
    "\n",
    "    formatted_context = \"\"\n",
    "\n",
    "    for id, chunk, rating in zip(retrieved_context_ids, retrieved_context, retrieved_context_ratings):\n",
    "        formatted_context += f\"- ID: {id}, rating: {rating}, description: {chunk}\\n\"\n",
    "\n",
    "    return formatted_context\n",
    "\n",
    "\n",
    "@traceable(\n",
    "    name=\"retriever_node\",\n",
    "    run_type=\"retriever\"\n",
    ")\n",
    "def retriever_node(state: State) -> dict:\n",
    "\n",
    "    retrieved_context = []\n",
    "\n",
    "    for query in state.expanded_query:\n",
    "        retrieved_context.append(retrieve_data(query, k=5))\n",
    "\n",
    "    return {\n",
    "        \"retrieved_context\": retrieved_context\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33c803d",
   "metadata": {},
   "source": [
    "#### Aggregator Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70526fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregatorResponse(BaseModel):\n",
    "    answer: str = Field(description=\"Answer to the question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e14ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"aggregator_node\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1-mini\"}\n",
    ")\n",
    "def aggregator_node(state: State) -> dict:\n",
    "\n",
    "   preprocessed_context = \"\\n\".join(state.retrieved_context)\n",
    "\n",
    "   prompt_template =  \"\"\"You are a shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "You will be given a question and a list of context.\n",
    "\n",
    "Instructions:\n",
    "- You need to answer the question based on the provided context only.\n",
    "- Never use word context and refer to it as the available products.\n",
    "- The answer to the question should contain detailed information about the product and returned with detailed specification in bullet points.\n",
    "\n",
    "Context:\n",
    "{{ preprocessed_context }}\n",
    "\n",
    "Question:\n",
    "{{ question }}\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      preprocessed_context=preprocessed_context,\n",
    "      question=state.initial_query\n",
    "   )\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        response_model=AggregatorResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   return {\n",
    "      \"answer\": response.answer\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"query_expand_node\", query_expand_node)\n",
    "workflow.add_node(\"retriever_node\", retriever_node)\n",
    "workflow.add_node(\"aggregator_node\", aggregator_node)\n",
    "\n",
    "workflow.add_edge(START, \"query_expand_node\")\n",
    "workflow.add_edge(\"query_expand_node\", \"retriever_node\")\n",
    "workflow.add_edge(\"retriever_node\", \"aggregator_node\")\n",
    "workflow.add_edge(\"aggregator_node\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b24115",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can I get a tablet for my kid, a watch for me and a laptop for my wife?\"\n",
    "initial_state = {\n",
    "    \"initial_query\": query,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e181e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbc4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d110dee",
   "metadata": {},
   "source": [
    "#### Query Expansion (Parallel Execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    expanded_query: List[str] = []\n",
    "    retrieved_context: Annotated[List[str], add] = []\n",
    "    initial_query: str = \"\"\n",
    "    answer: str = \"\"\n",
    "    query: str = \"\"\n",
    "    k: int = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ad4ed",
   "metadata": {},
   "source": [
    "#### Query Expansion / Rewriting Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dad54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpandResponse(BaseModel):\n",
    "   expanded_query: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb185c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"query_expand_node\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1-mini\"}\n",
    ")\n",
    "def query_expand_node(state: State) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are part of a shopping assistant that can answer questions about products in stock.\n",
    "\n",
    "Instructions:\n",
    "- You will be given a question and you need to expand it into a list of statements that can be used in contextual search to retrieve relevant products.\n",
    "- The statements should not overlap in context.\n",
    "- The answer to the question should contain detailed information about the product and returned with detailed specification in bullet points.\n",
    "\n",
    "<Question>\n",
    "{{ query }}\n",
    "</Question>\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      query=state.initial_query\n",
    "   )\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        response_model=QueryExpandResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   return {\n",
    "      \"expanded_query\": response.expanded_query\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expand_conditional_edges(state: State):\n",
    "\n",
    "    send_messages = []\n",
    "\n",
    "    for query in state.expanded_query:\n",
    "        send_messages.append(\n",
    "            Send(\n",
    "                \"retrieve_node\",\n",
    "                {\n",
    "                    \"query\": query,\n",
    "                    \"k\": 10\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return send_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb77c6",
   "metadata": {},
   "source": [
    "#### Retriever Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"embed_query\",\n",
    "    run_type=\"embedding\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"text-embedding-3-small\"}\n",
    ")\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model,\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "@traceable(\n",
    "    name=\"retrieve_top_n\",\n",
    "    run_type=\"retriever\"\n",
    ")\n",
    "def retrieve_node(state: State) -> dict:\n",
    "\n",
    "    qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "    query_embedding = get_embedding(state[\"query\"])\n",
    "\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"Amazon-items-collection-01-hybrid-search\",\n",
    "        prefetch=[\n",
    "            Prefetch(\n",
    "                query=query_embedding,\n",
    "                using=\"text-embedding-3-small\",\n",
    "                limit=20\n",
    "            ),\n",
    "            Prefetch(\n",
    "                query=Document(\n",
    "                    text=query,\n",
    "                    model=\"qdrant/bm25\"\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=20\n",
    "            )\n",
    "        ],\n",
    "        query=FusionQuery(fusion=\"rrf\"),\n",
    "        limit=state[\"k\"],\n",
    "    )\n",
    "\n",
    "    retrieved_context_ids = []\n",
    "    retrieved_context = []\n",
    "    similarity_scores = []\n",
    "    retrieved_context_ratings = []\n",
    "\n",
    "    for result in results.points:\n",
    "        retrieved_context_ids.append(result.payload[\"parent_asin\"])\n",
    "        retrieved_context.append(result.payload[\"description\"])\n",
    "        retrieved_context_ratings.append(result.payload[\"average_rating\"])\n",
    "        similarity_scores.append(result.score)\n",
    "\n",
    "    formatted_context = \"\"\n",
    "\n",
    "    for id, chunk, rating in zip(retrieved_context_ids, retrieved_context, retrieved_context_ratings):\n",
    "        formatted_context += f\"- ID: {id}, rating: {rating}, description: {chunk}\\n\"\n",
    "\n",
    "    return {\n",
    "        \"retrieved_context\": [formatted_context]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794ad68",
   "metadata": {},
   "source": [
    "#### Aggregator Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregatorResponse(BaseModel):\n",
    "    answer: str = Field(description=\"Answer to the question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85632490",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"aggregator_node\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1-mini\"}\n",
    ")\n",
    "def aggregator_node(state: State) -> dict:\n",
    "\n",
    "   preprocessed_context = \"\\n\".join(state.retrieved_context)\n",
    "\n",
    "   prompt_template =  \"\"\"You are a shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "You will be given a question and a list of context.\n",
    "\n",
    "Instructions:\n",
    "- You need to answer the question based on the provided context only.\n",
    "- Never use word context and refer to it as the available products.\n",
    "- The answer to the question should contain detailed information about the product and returned with detailed specification in bullet points.\n",
    "\n",
    "Context:\n",
    "{{ preprocessed_context }}\n",
    "\n",
    "Question:\n",
    "{{ question }}\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      preprocessed_context=preprocessed_context,\n",
    "      question=state.initial_query\n",
    "   )\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        response_model=AggregatorResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   return {\n",
    "      \"answer\": response.answer\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d710485",
   "metadata": {},
   "source": [
    "#### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"query_expand_node\", query_expand_node)\n",
    "workflow.add_node(\"retrieve_node\", retrieve_node)\n",
    "workflow.add_node(\"aggregator_node\", aggregator_node)\n",
    "\n",
    "workflow.add_edge(START, \"query_expand_node\")\n",
    "workflow.add_conditional_edges(\"query_expand_node\", query_expand_conditional_edges)\n",
    "\n",
    "workflow.add_edge(\"retrieve_node\", \"aggregator_node\")\n",
    "workflow.add_edge(\"aggregator_node\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20197864",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can I get a tablet for my kid, a watch for me and a laptop for my wife?\"\n",
    "initial_state = {\n",
    "    \"initial_query\": query,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e532e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac2a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c762d7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
