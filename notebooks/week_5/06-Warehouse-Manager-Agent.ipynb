{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a92ab41",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c88e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Prefetch, Filter, FieldCondition, MatchText, FusionQuery, Document\n",
    "\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Send, Command\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage, convert_to_openai_messages\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional, Sequence\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json\n",
    "\n",
    "from utils.utils import get_tool_descriptions, format_ai_message\n",
    "from utils.tools import add_to_shopping_cart, get_shopping_cart, remove_from_cart, get_formatted_items_context, get_formatted_reviews_context, check_warehouse_availability, reserve_warehouse_items\n",
    "\n",
    "from langgraph.checkpoint.postgres import PostgresSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f7ecf",
   "metadata": {},
   "source": [
    "## Worker Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b491511c",
   "metadata": {},
   "source": [
    "### Product QA Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: str = Field(description=\"The ID of the item used to answer the question\")\n",
    "    description: str = Field(description=\"Short description of the item used to answer the question\")\n",
    "    \n",
    "class ProductQAAgentResponse(BaseModel):\n",
    "    answer: str = Field(description=\"Answer to the question.\")\n",
    "    references: list[RAGUsedContext] = Field(description=\"List of items used to answer the question.\")\n",
    "    final_answer: bool = False\n",
    "    tool_calls: List[ToolCall] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86077463",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"product_qa_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def product_qa_agent(state) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a part of shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "You will be given a conversation history and a list of tools you can use to answer the latest query.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "When making tool calls, use this exact format:\n",
    "{\n",
    "\"name\": \"tool_name\",\n",
    "\"arguments\": {\n",
    "    \"parameter1\": \"value1\",\n",
    "    \"parameter2\": \"value2\",\n",
    "}\n",
    "}\n",
    "\n",
    "CRITICAL: All parameters must go inside the \"arguments\" object, not at the top level of the tool call.\n",
    "\n",
    "Examples:\n",
    "- Get formatted item context:\n",
    "{\n",
    "\"name\": \"get_formatted_item_context\",\n",
    "\"arguments\": {\n",
    "    \"query\": \"Kool kids toys.\",\n",
    "    \"top_k\": 5\n",
    "}\n",
    "}\n",
    "\n",
    "- Get formatted user reviews:\n",
    "{\n",
    "\"name\": \"get_formatted_reviews_context\",\n",
    "\"arguments\": {\n",
    "    \"query\": \"Durable.\",\n",
    "    \"item_list\": [\"123\", \"456\"],\n",
    "    \"top_k\": 5\n",
    "}\n",
    "}\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If tool_calls has values, final_answer MUST be false\n",
    "(You cannot call tools and exit the graph in the same response)\n",
    "- If final_answer is true, tool_calls MUST be []\n",
    "(You must wait for tool results before exiting the graph)\n",
    "- If you need tool results before answering, set:\n",
    "tool_calls=[...], final_answer=false\n",
    "- After receiving tool results, you can then set:\n",
    "tool_calls=[], final_answer=true\n",
    "- Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "\n",
    "Instructions:\n",
    "- You need to answer the question based on the outputs from the tools using the available tools only.\n",
    "- Do not suggest the same tool call more than once.\n",
    "- If the question can be decomposed into multiple sub-questions, suggest all of them.\n",
    "- If multipple tool calls can be used at once to answer the question, suggest all of them.\n",
    "- Do not explain your next steps in the answer, instead use tools to answer the question.\n",
    "- Never use word context and refer to it as the available products.\n",
    "- You should only answer questions about the products in stock. If the question is not about the products in stock, you should ask for clarification.\n",
    "- As an output you need to return the following:\n",
    "\n",
    "* answer: The answer to the question based on your current knowledge and the tool results.\n",
    "* references: The list of the indexes from the chunks returned from all tool calls that were used to answer the question. If more than one chunk was used to compile the answer from a single tool call, be sure to return all of them.\n",
    "* Each reference should have an id and a short description of the item based on the retrieved context.\n",
    "* final_answer: True if you have all the information needed to provide a complete answer, False otherwise.\n",
    "\n",
    "- The answer to the question should contain detailed information about the product and should be returned with detailed specification in bullet points.\n",
    "- The short description should have the name of the item.\n",
    "- If the user's request requires using a tool, set tool_calls with the appropriate function names and arguments.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.product_qa_agent.available_tools\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ProductQAAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   ai_message = format_ai_message(response)\n",
    "\n",
    "   return {\n",
    "        \"messages\": [ai_message],\n",
    "        \"product_qa_agent\": {\n",
    "            \"tool_calls\": [tool_call.model_dump() for tool_call in response.tool_calls],\n",
    "            \"iteration\": state.product_qa_agent.iteration + 1,\n",
    "            \"final_answer\": response.final_answer,\n",
    "            \"available_tools\": state.product_qa_agent.available_tools\n",
    "        },\n",
    "        \"answer\": response.answer,\n",
    "        \"references\": response.references\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe7642b",
   "metadata": {},
   "source": [
    "### Shopping Cart Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "    \n",
    "class ShoppingCartAgentResponse(BaseModel):\n",
    "    answer: str = Field(description=\"Answer to the question.\")\n",
    "    final_answer: bool = False\n",
    "    tool_calls: List[ToolCall] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"shopping_cart_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def shopping_cart_agent(state) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a part of the shopping assistant that can manage the user's shopping cart.\n",
    "\n",
    "You will be given a conversation history and a list of tools, your task is to perform the action requested by the latest user query.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "When making tool calls, use this exact format:\n",
    "{\n",
    "   \"name\": \"tool_name\",\n",
    "   \"arguments\": {\n",
    "         \"parameter1\": \"value1\",\n",
    "         \"parameter2\": \"value2\",\n",
    "   }\n",
    "}\n",
    "\n",
    "CRITICAL: All parameters must go inside the \"arguments\" object, not at the top level of the tool call.\n",
    "\n",
    "Examples:\n",
    "- Remove item from shopping cart:\n",
    "{\n",
    "   \"name\": \"remove_from_shopping_cart\",\n",
    "   \"arguments\": {\n",
    "         \"product_id\": \"123\",\n",
    "         \"user_id\": \"123\",\n",
    "         \"cart_id\": \"456\"\n",
    "   }\n",
    "}\n",
    "\n",
    "- Add item to shopping cart:\n",
    "{\n",
    "   \"name\": \"add_to_shopping_cart\",\n",
    "   \"arguments\": {\n",
    "         \"items\": [\n",
    "            {\n",
    "               \"product_id\": \"123\",\n",
    "               \"quantity\": 1\n",
    "            },\n",
    "            {\n",
    "               \"product_id\": \"456\",\n",
    "               \"quantity\": 2\n",
    "            }\n",
    "         ],\n",
    "         \"user_id\": \"123\",\n",
    "         \"cart_id\": \"456\"\n",
    "   }\n",
    "}\n",
    "\n",
    "- Get shopping cart:\n",
    "{\n",
    "   \"name\": \"get_shopping_cart\",\n",
    "   \"arguments\": {\n",
    "         \"user_id\": \"123\",\n",
    "         \"cart_id\": \"456\"\n",
    "   }\n",
    "}\n",
    "\n",
    "After the tools are used you will get the outputs from the tools.\n",
    "\n",
    "Additional information:\n",
    "- User ID: {{ user_id }}\n",
    "- Cart ID: {{ cart_id }}\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If tool_calls has values, final_answer MUST be false\n",
    "(You cannot call tools and return to coordinator in the same response)\n",
    "- If final_answer is true, tool_calls MUST be []\n",
    "(You must wait for tool results before returning to coordinator)\n",
    "- If you need tool results before answering, set:\n",
    "tool_calls=[...], final_answer=false\n",
    "- After receiving tool results, you can then set:\n",
    "tool_calls=[], final_answer=true\n",
    "\n",
    "Instructions:\n",
    "- Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "- You can run multipple tools at once.\n",
    "- Once you get the tool results back, you might choose to performa additional tool calls.\n",
    "- Once your suggested tool calls are done, set final_answer to True.\n",
    "- Never set final_answer to True if you are suggesting tool_calls.\n",
    "- As the final answer you should return an answer to the users query in a form of actions performed.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.shopping_cart_agent.available_tools,\n",
    "      user_id=state.user_id,\n",
    "      cart_id=state.cart_id\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ShoppingCartAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   ai_message = format_ai_message(response)\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"shopping_cart_agent\": {\n",
    "         \"iteration\": state.shopping_cart_agent.iteration + 1,\n",
    "         \"final_answer\": response.final_answer,\n",
    "         \"tool_calls\": [tool_call.model_dump() for tool_call in response.tool_calls],\n",
    "         \"available_tools\": state.shopping_cart_agent.available_tools\n",
    "      },\n",
    "      \"answer\": response.answer\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40603f38",
   "metadata": {},
   "source": [
    "### Warehouse Manager Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "    \n",
    "class WarehouseManagerAgentResponse(BaseModel):\n",
    "    answer: str = Field(description=\"Answer to the question.\")\n",
    "    final_answer: bool = False\n",
    "    tool_calls: List[ToolCall] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671fd858",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"warehouse_manager_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def warehouse_manager_agent(state) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a part of the shopping assistant that can manage available inventory in the warehouses.\n",
    "\n",
    "You will be given a conversation history and a list of tools, your task is to perform actions requested by the latest user query. Answer part of the query that you can answer with the available tools.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "When making tool calls, use this exact format:\n",
    "{\n",
    "   \"name\": \"tool_name\",\n",
    "   \"arguments\": {\n",
    "         \"parameter1\": \"value1\",\n",
    "         \"parameter2\": \"value2\",\n",
    "   }\n",
    "}\n",
    "\n",
    "CRITICAL: All parameters must go inside the \"arguments\" object, not at the top level of the tool call.\n",
    "\n",
    "Examples:\n",
    "- Check warehouse availability:\n",
    "{\n",
    "   \"name\": \"check_warehouse_availability\",\n",
    "   \"arguments\": {\n",
    "         \"items\": [\n",
    "            {\n",
    "                \"product_id\": \"123\",\n",
    "                \"quantity\": 5\n",
    "            },\n",
    "            {\n",
    "                \"product_id\": \"456\",\n",
    "                \"quantity\": 10\n",
    "            },\n",
    "            {\n",
    "                \"product_id\": \"789\",\n",
    "                \"quantity\": 20\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "- Reserve warehouse items:\n",
    "{\n",
    "   \"name\": \"reserve_warehouse_items\",\n",
    "   \"arguments\": {\n",
    "         \"reservations\": [\n",
    "            {\n",
    "                \"warehouse_id\": \"abc\",\n",
    "                \"product_id\": \"123\",\n",
    "                \"quantity\": 10\n",
    "            },\n",
    "            {\n",
    "                \"warehouse_id\": \"def\",\n",
    "                \"product_id\": \"456\",\n",
    "                \"quantity\": 10\n",
    "            }   \n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "After the tools are used you will get the outputs from the tools.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If tool_calls has values, final_answer MUST be false\n",
    "(You cannot call tools and return to coordinator in the same response)\n",
    "- If final_answer is true, tool_calls MUST be []\n",
    "(You must wait for tool results before returning to coordinator)\n",
    "- If you need tool results before answering, set:\n",
    "tool_calls=[...], final_answer=false\n",
    "- After receiving tool results, you can then set:\n",
    "tool_calls=[], final_answer=true\n",
    "\n",
    "Instructions:\n",
    "- Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "- You can run multipple tools at once.\n",
    "- Once you get the tool results back, you might choose to performa additional tool calls.\n",
    "- Once your suggested tool calls are done, set final_answer to True.\n",
    "- Never set final_answer to True if you are suggesting tool_calls.\n",
    "- As the final answer you should return an answer to the users query in a form of actions performed.\n",
    "- You must always check the availability of the items in the warehouses before reserving them.\n",
    "- Only reserve items in warehouses if entire order can be reserved or the user has confirmed that they want a partial reservation.\n",
    "- If you cannot reserve any items, return an answer that the order cannot be reserved.\n",
    "- If you can reserve some items, return an answer that the order can be partially reserved and include the details.\n",
    "- If only partial quantity can be reserved in some warehouses, try to combine the required quantity from different warehouses.\n",
    "- Try to reserve items from the closest warehouse to the user first if users location is provided.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.warehouse_manager_agent.available_tools\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ShoppingCartAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   ai_message = format_ai_message(response)\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"warehouse_manager_agent\": {\n",
    "         \"iteration\": state.warehouse_manager_agent.iteration + 1,\n",
    "         \"final_answer\": response.final_answer,\n",
    "         \"tool_calls\": [tool_call.model_dump() for tool_call in response.tool_calls],\n",
    "         \"available_tools\": state.warehouse_manager_agent.available_tools\n",
    "      },\n",
    "      \"answer\": response.answer\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd08da",
   "metadata": {},
   "source": [
    "## Coordinator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14baa016",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Delegation(BaseModel):\n",
    "    agent: str\n",
    "    task: str\n",
    "\n",
    "class CoordinatorAgentResponse(BaseModel):\n",
    "    next_agent: str\n",
    "    plan: List[Delegation]\n",
    "    final_answer: bool = False\n",
    "    answer: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78811ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"coordinator_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def coordinator_agent(state):\n",
    "\n",
    "   prompt_template =  \"\"\"You are a Coordinator Agent as part of a shopping assistant.\n",
    "\n",
    "Your role is to create plans for solving user queries and delegate the tasks accordingly.\n",
    "You will be given a conversation history, your task is to create a plan for solving the user's query.\n",
    "After the plan is created, you should output the next agent to invoke and the task to be performed by that agent.\n",
    "Once an agent finishes its task, you will be handed the control back, you should then review the conversation history and revise the plan.\n",
    "If there is a sequence of tasks to be performed by a single agent, you should combine them into a single task.\n",
    "\n",
    "The possible agents are:\n",
    "\n",
    "- product_qa_agent: The user is asking a question about a product. This can be a question about available products, their specifications, user reviews etc.\n",
    "- shopping_cart_agent: The user is asking to add or remove items from the shopping cart or questions about the current shopping cart.\n",
    "- warehouse_manager_agent: The user is asking to reserve items from the warehouses or about availability of the items in warehouses.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If next_agent is \"\", final_answer MUST be false\n",
    "(You cannot delegate the task to an agent and return to the user in the same response)\n",
    "- If final_answer is true, next_agent MUST be \"\"\n",
    "(You must wait for agent results before returning to user)\n",
    "- If you need to call other agents before answering, set:\n",
    "next_agent=\"...\", final_answer=false\n",
    "- After receiving agent results, you can then set:\n",
    "next_agent=\"\", final_answer=true\n",
    "- One of the following has to be true:\n",
    "next_agent is \"\" and final_answer is true\n",
    "next_agent is not \"\" and final_answer is false\n",
    "\n",
    "Additional instructions:\n",
    "\n",
    "- Do not route to any agent if the user's query needs clarification. Do it yourself.\n",
    "- Write the plan to the plan field.\n",
    "- Write the next agent to invoke to the next_agent field.\n",
    "- Once you have all the information needed to answer the user's query, you should set the final_answer field to True and output the answer to the user's query.\n",
    "- The final answer to the user query should be a comprehensive answer that explains the actions that were performed to answer the query.\n",
    "- Never set final_answer to true if the plan is not complete.\n",
    "- You should output the next_agent field as well as the plan field.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render()\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=CoordinatorAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   if response.final_answer:\n",
    "      ai_message = [AIMessage(\n",
    "         content=response.answer,\n",
    "      )]\n",
    "   else:\n",
    "      ai_message = []\n",
    "\n",
    "   return {\n",
    "      \"messages\": ai_message,\n",
    "      \"answer\": response.answer,\n",
    "      \"coordinator_agent\": {\n",
    "         \"iteration\": state.coordinator_agent.iteration + 1,\n",
    "         \"final_answer\": response.final_answer,\n",
    "         \"next_agent\": response.next_agent,\n",
    "         \"plan\": [data.model_dump() for data in response.plan]\n",
    "      }\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7f244c",
   "metadata": {},
   "source": [
    "### Product QA Agent Tool Use Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f40374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_qa_agent_tool_edge(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.product_qa_agent.final_answer:\n",
    "        return \"end\"\n",
    "    elif state.product_qa_agent.iteration > 4:\n",
    "        return \"end\"\n",
    "    elif len(state.product_qa_agent.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0afdfbe",
   "metadata": {},
   "source": [
    "### Shopping Cart Agent Tool Use Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ee475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shopping_cart_agent_tool_edge(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.shopping_cart_agent.final_answer:\n",
    "        return \"end\"\n",
    "    elif state.shopping_cart_agent.iteration > 2:\n",
    "        return \"end\"\n",
    "    elif len(state.shopping_cart_agent.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ffd329",
   "metadata": {},
   "source": [
    "### Warehouse Manager Agent Tool Use Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warehouse_manager_agent_tool_edge(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.warehouse_manager_agent.final_answer:\n",
    "        return \"end\"\n",
    "    elif state.warehouse_manager_agent.iteration > 2:\n",
    "        return \"end\"\n",
    "    elif len(state.warehouse_manager_agent.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468671c",
   "metadata": {},
   "source": [
    "### Coordinator Agent Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinator_agent_edge(state):\n",
    "\n",
    "    if state.coordinator_agent.iteration > 3:\n",
    "        return \"end\"\n",
    "    elif state.coordinator_agent.final_answer and len(state.coordinator_agent.plan) == 0:\n",
    "        return \"end\"\n",
    "    elif state.coordinator_agent.next_agent == \"product_qa_agent\":\n",
    "        return \"product_qa_agent\"\n",
    "    elif state.coordinator_agent.next_agent == \"shopping_cart_agent\":\n",
    "        return \"shopping_cart_agent\"\n",
    "    elif state.coordinator_agent.next_agent == \"warehouse_manager_agent\":\n",
    "        return \"warehouse_manager_agent\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9054ad0c",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cde201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentProperties(BaseModel):    \n",
    "    iteration: int = 0\n",
    "    final_answer: bool = False\n",
    "    available_tools: List[Dict[str, Any]] = []\n",
    "    tool_calls: List[ToolCall] = []\n",
    "\n",
    "\n",
    "class CoordinatorAgentProperties(BaseModel):    \n",
    "    iteration: int = 0\n",
    "    final_answer: bool = False\n",
    "    plan: List[Delegation] = []\n",
    "    next_agent: str = \"\"\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    user_intent: str = \"\"\n",
    "    product_qa_agent: AgentProperties = Field(default_factory=AgentProperties)\n",
    "    shopping_cart_agent: AgentProperties = Field(default_factory=AgentProperties)\n",
    "    warehouse_manager_agent: AgentProperties = Field(default_factory=AgentProperties)\n",
    "    coordinator_agent: CoordinatorAgentProperties = Field(default_factory=CoordinatorAgentProperties)\n",
    "    answer: str = \"\"\n",
    "    references: Annotated[List[RAGUsedContext], add] = []\n",
    "    user_id: str = \"\"\n",
    "    cart_id: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "product_qa_agent_tools = [get_formatted_items_context, get_formatted_reviews_context]\n",
    "product_qa_agent_tool_node = ToolNode(product_qa_agent_tools)\n",
    "product_qa_agent_tool_descriptions = get_tool_descriptions(product_qa_agent_tools)\n",
    "\n",
    "shopping_cart_agent_tools = [add_to_shopping_cart, remove_from_cart, get_shopping_cart]\n",
    "shopping_cart_agent_tool_node = ToolNode(shopping_cart_agent_tools)\n",
    "shopping_cart_agent_tool_descriptions = get_tool_descriptions(shopping_cart_agent_tools)\n",
    "\n",
    "warehouse_manager_agent_tools = [check_warehouse_availability, reserve_warehouse_items]\n",
    "warehouse_manager_agent_tool_node = ToolNode(warehouse_manager_agent_tools)\n",
    "warehouse_manager_agent_tool_descriptions = get_tool_descriptions(warehouse_manager_agent_tools)\n",
    "\n",
    "workflow.add_node(\"product_qa_agent\", product_qa_agent)\n",
    "workflow.add_node(\"shopping_cart_agent\", shopping_cart_agent)\n",
    "workflow.add_node(\"warehouse_manager_agent\", warehouse_manager_agent)\n",
    "workflow.add_node(\"coordinator_agent\", coordinator_agent)\n",
    "\n",
    "workflow.add_node(\"product_qa_agent_tool_node\", product_qa_agent_tool_node)\n",
    "workflow.add_node(\"shopping_cart_agent_tool_node\", shopping_cart_agent_tool_node)\n",
    "workflow.add_node(\"warehouse_manager_agent_tool_node\", warehouse_manager_agent_tool_node)\n",
    "workflow.add_edge(START, \"coordinator_agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"coordinator_agent\",\n",
    "    coordinator_agent_edge,\n",
    "    {\n",
    "        \"product_qa_agent\": \"product_qa_agent\",\n",
    "        \"shopping_cart_agent\": \"shopping_cart_agent\",\n",
    "        \"warehouse_manager_agent\": \"warehouse_manager_agent\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"product_qa_agent\",\n",
    "    product_qa_agent_tool_edge,\n",
    "    {\n",
    "        \"tools\": \"product_qa_agent_tool_node\",\n",
    "        \"end\": \"coordinator_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"shopping_cart_agent\",\n",
    "    shopping_cart_agent_tool_edge,\n",
    "    {\n",
    "        \"tools\": \"shopping_cart_agent_tool_node\",\n",
    "        \"end\": \"coordinator_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"warehouse_manager_agent\",\n",
    "    warehouse_manager_agent_tool_edge,\n",
    "    {\n",
    "        \"tools\": \"warehouse_manager_agent_tool_node\",\n",
    "        \"end\": \"coordinator_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"product_qa_agent_tool_node\", \"product_qa_agent\")\n",
    "workflow.add_edge(\"shopping_cart_agent_tool_node\", \"shopping_cart_agent\")\n",
    "workflow.add_edge(\"warehouse_manager_agent_tool_node\", \"warehouse_manager_agent\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b08cfe",
   "metadata": {},
   "source": [
    "### Test The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62525cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather today?\"}],\n",
    "    \"user_id\": \"123\",\n",
    "    \"cart_id\": \"456\",\n",
    "    \"product_qa_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": product_qa_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"shopping_cart_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": shopping_cart_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"warehouse_manager_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": warehouse_manager_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"coordinator_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"plan\": [],\n",
    "        \"next_agent\": \"\"\n",
    "    }\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": \"test99999999999992\"}}\n",
    "\n",
    "with PostgresSaver.from_conn_string(\"postgresql://langgraph_user:langgraph_password@localhost:5433/langgraph_db\") as checkpointer:\n",
    "\n",
    "    graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "    for chunk in graph.stream(\n",
    "        initial_state,\n",
    "        config=config,\n",
    "        stream_mode=[\"values\"]\n",
    "    ):\n",
    "        print(chunk)\n",
    "        if chunk[0] == \"values\":\n",
    "            result_1 = chunk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49882237",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_1[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can I get some earphones and a laptop bag? Could you get user reviews for these and add the best reviewed items to my shopping cart? Could you then also reserve these items in your warehouses?\"}],\n",
    "    \"user_id\": \"123\",\n",
    "    \"cart_id\": \"456\",\n",
    "    \"product_qa_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": product_qa_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"shopping_cart_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": shopping_cart_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"warehouse_manager_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": warehouse_manager_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"coordinator_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"plan\": [],\n",
    "        \"next_agent\": \"\"\n",
    "    }\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": \"test99999999uioui99iop3goyyo\"}}\n",
    "\n",
    "with PostgresSaver.from_conn_string(\"postgresql://langgraph_user:langgraph_password@localhost:5433/langgraph_db\") as checkpointer:\n",
    "\n",
    "    graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "    for chunk in graph.stream(\n",
    "        initial_state,\n",
    "        config=config,\n",
    "        stream_mode=[\"values\"]\n",
    "    ):\n",
    "        print(chunk)\n",
    "        if chunk[0] == \"values\":\n",
    "            result_2 = chunk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb31b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810fa948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
