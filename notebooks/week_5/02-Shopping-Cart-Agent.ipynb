{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4549215f",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Prefetch, Filter, FieldCondition, MatchText, FusionQuery, Document\n",
    "\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Send, Command\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage, convert_to_openai_messages\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional, Sequence\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json\n",
    "\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "from utils.utils import get_tool_descriptions, format_ai_message\n",
    "from utils.tools import get_formatted_items_context, get_formatted_reviews_context, get_shopping_cart, add_to_shopping_cart, remove_from_cart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e518b04",
   "metadata": {},
   "source": [
    "## Worker Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7939194",
   "metadata": {},
   "source": [
    "### Product QnA Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGUsedContext(BaseModel):\n",
    "    id: str = Field(description=\"The ID of the item used to answer the question\")\n",
    "    description: str = Field(description=\"Short description of the item used to answer the question\")\n",
    "    \n",
    "class ProductQAAgentResponse(BaseModel):\n",
    "    answer: str = Field(description=\"Answer to the question.\")\n",
    "    references: list[RAGUsedContext] = Field(description=\"List of items used to answer the question.\")\n",
    "    final_answer: bool = False\n",
    "    tool_calls: List[ToolCall] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"product_qa_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def product_qa_agent(state) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "    You will be given a conversation history and a list of tools you can use to answer the latest query.\n",
    "\n",
    "    <Available tools>\n",
    "    {{ available_tools | tojson }}\n",
    "    </Available tools>\n",
    "\n",
    "    When making tool calls, use this exact format:\n",
    "    {\n",
    "        \"name\": \"tool_name\",\n",
    "        \"arguments\": {\n",
    "            \"parameter1\": \"value1\",\n",
    "            \"parameter2\": \"value2\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    CRITICAL: All parameters must go inside the \"arguments\" object, not at the top level of the tool call.\n",
    "\n",
    "    Examples:\n",
    "    - Get formatted item context:\n",
    "    {\n",
    "        \"name\": \"get_formatted_item_context\",\n",
    "        \"arguments\": {\n",
    "            \"query\": \"Kool kids toys.\",\n",
    "            \"top_k\": 5\n",
    "        }\n",
    "    }\n",
    "\n",
    "    - Get formatted user reviews:\n",
    "    {\n",
    "        \"name\": \"get_formatted_reviews_context\",\n",
    "        \"arguments\": {\n",
    "            \"query\": \"Durable.\",\n",
    "            \"item_list\": [\"123\", \"456\"],\n",
    "            \"top_k\": 5\n",
    "        }\n",
    "    }\n",
    "\n",
    "    CRITICAL RULES:\n",
    "    - If tool_calls has values, final_answer MUST be false\n",
    "    (You cannot call tools and exit the graph in the same response)\n",
    "    - If final_answer is true, tool_calls MUST be []\n",
    "    (You must wait for tool results before exiting the graph)\n",
    "    - If you need tool results before answering, set:\n",
    "    tool_calls=[...], final_answer=false\n",
    "    - After receiving tool results, you can then set:\n",
    "    tool_calls=[], final_answer=true\n",
    "    - Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "\n",
    "    Instructions:\n",
    "    - You need to answer the question based on the outputs from the tools using the available tools only.\n",
    "    - Do not suggest the same tool call more than once.\n",
    "    - If the question can be decomposed into multiple sub-questions, suggest all of them.\n",
    "    - If multipple tool calls can be used at once to answer the question, suggest all of them.\n",
    "    - Do not explain your next steps in the answer, instead use tools to answer the question.\n",
    "    - Never use word context and refer to it as the available products.\n",
    "    - You should only answer questions about the products in stock. If the question is not about the products in stock, you should ask for clarification.\n",
    "    - As an output you need to return the following:\n",
    "\n",
    "    * answer: The answer to the question based on your current knowledge and the tool results.\n",
    "    * references: The list of the indexes from the chunks returned from all tool calls that were used to answer the question. If more than one chunk was used to compile the answer from a single tool call, be sure to return all of them.\n",
    "    * Each reference should have an id and a short description of the item based on the retrieved context.\n",
    "    * final_answer: True if you have all the information needed to provide a complete answer, False otherwise.\n",
    "\n",
    "    - The answer to the question should contain detailed information about the product and should be returned with detailed specification in bullet points.\n",
    "    - The short description should have the name of the item.\n",
    "    - If the user's request requires using a tool, set tool_calls with the appropriate function names and arguments.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.product_qa_agent.available_tools\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ProductQAAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   ai_message = format_ai_message(response)\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"product_qa_agent\": {\n",
    "        \"tool_calls\": [tool_call.model_dump() for tool_call in response.tool_calls],\n",
    "        \"iteration\": state.product_qa_agent.iteration + 1,\n",
    "        \"final_answer\": response.final_answer,\n",
    "        \"available_tools\": state.product_qa_agent.available_tools\n",
    "      },\n",
    "      \"answer\": response.answer,\n",
    "      \"references\": response.references\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e2d3c9",
   "metadata": {},
   "source": [
    "### Shopping Cart Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShoppingCartAgentResponse(BaseModel):\n",
    "    answer: str = Field(description=\"Answer to the question.\")\n",
    "    final_answer: bool = False\n",
    "    tool_calls: List[ToolCall] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e833d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"shopping_cart_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def shopping_cart_agent(state) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a part of the shopping assistant that can manage the user's shopping cart.\n",
    "\n",
    "You will be given a conversation history and a list of tools, your task is to perform the action requested by the latest user query.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "When making tool calls, use this exact format:\n",
    "{\n",
    "   \"name\": \"tool_name\",\n",
    "   \"arguments\": {\n",
    "         \"parameter1\": \"value1\",\n",
    "         \"parameter2\": \"value2\",\n",
    "   }\n",
    "}\n",
    "\n",
    "CRITICAL: All parameters must go inside the \"arguments\" object, not at the top level of the tool call.\n",
    "\n",
    "Examples:\n",
    "- Remove item from shopping cart:\n",
    "{\n",
    "   \"name\": \"remove_from_shopping_cart\",\n",
    "   \"arguments\": {\n",
    "         \"product_id\": \"123\",\n",
    "         \"user_id\": \"123\",\n",
    "         \"cart_id\": \"456\"\n",
    "   }\n",
    "}\n",
    "\n",
    "- Add item to shopping cart:\n",
    "{\n",
    "   \"name\": \"add_to_shopping_cart\",\n",
    "   \"arguments\": {\n",
    "         \"items\": [\n",
    "            {\n",
    "               \"product_id\": \"123\",\n",
    "               \"quantity\": 1\n",
    "            },\n",
    "            {\n",
    "               \"product_id\": \"456\",\n",
    "               \"quantity\": 2\n",
    "            }\n",
    "         ],\n",
    "         \"user_id\": \"123\",\n",
    "         \"cart_id\": \"456\"\n",
    "   }\n",
    "}\n",
    "\n",
    "- Get shopping cart:\n",
    "{\n",
    "   \"name\": \"get_shopping_cart\",\n",
    "   \"arguments\": {\n",
    "         \"user_id\": \"123\",\n",
    "         \"cart_id\": \"456\"\n",
    "   }\n",
    "}\n",
    "\n",
    "After the tools are used you will get the outputs from the tools.\n",
    "\n",
    "Additional information:\n",
    "- User ID: {{ user_id }}\n",
    "- Cart ID: {{ cart_id }}\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If tool_calls has values, final_answer MUST be false\n",
    "(You cannot call tools and return to coordinator in the same response)\n",
    "- If final_answer is true, tool_calls MUST be []\n",
    "(You must wait for tool results before returning to coordinator)\n",
    "- If you need tool results before answering, set:\n",
    "tool_calls=[...], final_answer=false\n",
    "- After receiving tool results, you can then set:\n",
    "tool_calls=[], final_answer=true\n",
    "\n",
    "Instructions:\n",
    "- Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "- You can run multipple tools at once.\n",
    "- Once you get the tool results back, you might choose to performa additional tool calls.\n",
    "- Once your suggested tool calls are done, set final_answer to True.\n",
    "- Never set final_answer to True if you are suggesting tool_calls.\n",
    "- As the final answer you should return an answer to the users query in a form of actions performed.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.shopping_cart_agent.available_tools,\n",
    "      user_id=state.user_id,\n",
    "      cart_id=state.cart_id\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ShoppingCartAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   ai_message = format_ai_message(response)\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"shopping_cart_agent\": {\n",
    "        \"tool_calls\": [tool_call.model_dump() for tool_call in response.tool_calls],\n",
    "        \"iteration\": state.shopping_cart_agent.iteration + 1,\n",
    "        \"final_answer\": response.final_answer,\n",
    "        \"available_tools\": state.shopping_cart_agent.available_tools\n",
    "      },\n",
    "      \"answer\": response.answer,\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df52b2fe",
   "metadata": {},
   "source": [
    "## Intent Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc976117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentRouterResponse(BaseModel):\n",
    "    user_intent: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"intent_router_node\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def intent_router_node(state):\n",
    "\n",
    "   prompt_template =  \"\"\"You are a part of a shopping assistant that routes user queries to the appropriate agents.\n",
    "\n",
    "You will be given a conversation history, your task is to classify the intent of the user's latest query and output an appropriate classification.\n",
    "\n",
    "The possible intents are:\n",
    "\n",
    "- product_qa: The user is asking a question about a product. This can be a question about available products, their specifications, user reviews etc.\n",
    "- shopping_cart: The user is asking to add or remove items from the shopping cart or questions about the current shopping cart.\n",
    "- other: The user's latest query is not clear or not related to the shopping assistant.\n",
    "\n",
    "Additional instructions:\n",
    "\n",
    "- Write the intent classification to the user_intent field.\n",
    "- If there is not enough context in the conversation history about the actions needed to be performed, do not classify as 'shopping_cart' or 'product_qa', instead classify as 'other'.\n",
    "- If the classification is 'other', you should output the answer to the user's query trying to clarify the user's intent.\n",
    "- If the classification is 'product_qa' or 'shopping_cart', you should only output the intent classification and no other text.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render()\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=IntentRouterResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   if response.user_intent == \"product_qa\":\n",
    "      ai_message = []\n",
    "   elif response.user_intent == \"shopping_cart\":\n",
    "      ai_message = []\n",
    "   else:\n",
    "      ai_message = [AIMessage(\n",
    "         content=response.answer,\n",
    "      )]\n",
    "\n",
    "   return {\n",
    "      \"messages\": ai_message,\n",
    "      \"user_intent\": response.user_intent,\n",
    "      \"answer\": response.answer\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f19cdb",
   "metadata": {},
   "source": [
    "#### Product QA Agent Tool Router Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bb49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_qa_agent_tool_router(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.product_qa_agent.final_answer:\n",
    "        return \"end\"\n",
    "    elif state.product_qa_agent.iteration > 4:\n",
    "        return \"end\"\n",
    "    elif len(state.product_qa_agent.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d4e",
   "metadata": {},
   "source": [
    "#### Shopping Cart Agent Tool Router Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shopping_cart_agent_tool_router(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.shopping_cart_agent.final_answer:\n",
    "        return \"end\"\n",
    "    elif state.shopping_cart_agent.iteration > 2:\n",
    "        return \"end\"\n",
    "    elif len(state.shopping_cart_agent.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b720f8",
   "metadata": {},
   "source": [
    "#### User Intent Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686188ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_intent_router(state):\n",
    "\n",
    "    if state.user_intent == \"product_qa\":\n",
    "        return \"product_qa_agent\"\n",
    "    elif state.user_intent == \"shopping_cart\":\n",
    "        return \"shopping_cart_agent\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba23cc3",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentProperties(BaseModel):\n",
    "    iteration: int = 0\n",
    "    available_tools: List[Dict[str, Any]] = []\n",
    "    tool_calls: List[ToolCall] = []\n",
    "    final_answer: bool = False\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    user_intent: str = \"\"\n",
    "    product_qa_agent: AgentProperties = Field(default_factory=AgentProperties)\n",
    "    shopping_cart_agent: AgentProperties = Field(default_factory=AgentProperties)\n",
    "    answer: str = \"\"\n",
    "    user_id: str = \"\"\n",
    "    cart_id: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739347eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "product_qa_agent_tools = [get_formatted_items_context, get_formatted_reviews_context]\n",
    "product_qa_agent_tool_node = ToolNode(product_qa_agent_tools)\n",
    "product_qa_agent_tool_descriptions = get_tool_descriptions(product_qa_agent_tools)\n",
    "\n",
    "shopping_cart_agent_tools = [add_to_shopping_cart, remove_from_cart, get_shopping_cart]\n",
    "shopping_cart_agent_tool_node = ToolNode(shopping_cart_agent_tools)\n",
    "shopping_cart_agent_tool_descriptions = get_tool_descriptions(shopping_cart_agent_tools)\n",
    "\n",
    "workflow.add_node(\"product_qa_agent\", product_qa_agent)\n",
    "workflow.add_node(\"shopping_cart_agent\", shopping_cart_agent)\n",
    "workflow.add_node(\"intent_router\", intent_router_node)\n",
    "\n",
    "workflow.add_node(\"product_qa_agent_tool_node\", product_qa_agent_tool_node)\n",
    "workflow.add_node(\"shopping_cart_agent_tool_node\", shopping_cart_agent_tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"intent_router\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"intent_router\",\n",
    "    user_intent_router,\n",
    "    {\n",
    "        \"product_qa_agent\": \"product_qa_agent\",\n",
    "        \"shopping_cart_agent\": \"shopping_cart_agent\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"product_qa_agent\",\n",
    "    product_qa_agent_tool_router,\n",
    "    {\n",
    "        \"tools\": \"product_qa_agent_tool_node\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"shopping_cart_agent\",\n",
    "    shopping_cart_agent_tool_router,\n",
    "    {\n",
    "        \"tools\": \"shopping_cart_agent_tool_node\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"product_qa_agent_tool_node\", \"product_qa_agent\")\n",
    "workflow.add_edge(\"shopping_cart_agent_tool_node\", \"shopping_cart_agent\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ed43e",
   "metadata": {},
   "source": [
    "### Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ed131",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather today?\"}],\n",
    "    \"user_id\": \"123456\",\n",
    "    \"cart_id\": \"abcdefg\",\n",
    "    \"product_qa_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": product_qa_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"shopping_cart_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": shopping_cart_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    }\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": \"test111111111111111111111\"}}\n",
    "\n",
    "with PostgresSaver.from_conn_string(\"postgresql://langgraph_user:langgraph_password@localhost:5433/langgraph_db\") as checkpointer:\n",
    "\n",
    "    graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "    for chunk in graph.stream(\n",
    "        initial_state,\n",
    "        config=config,\n",
    "        stream_mode=[\"values\"]\n",
    "    ):\n",
    "        print(chunk)\n",
    "        if chunk[0] == \"values\":\n",
    "            result_1 = chunk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95169a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_1[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can i get some earphones and a laptop? Could you also give me some positive and negative reviews about each suggestion?\"}],\n",
    "    \"user_id\": \"123456\",\n",
    "    \"cart_id\": \"abcdefg\",\n",
    "    \"product_qa_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": product_qa_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"shopping_cart_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": shopping_cart_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    }\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": \"test111111111111111111114\"}}\n",
    "\n",
    "with PostgresSaver.from_conn_string(\"postgresql://langgraph_user:langgraph_password@localhost:5433/langgraph_db\") as checkpointer:\n",
    "\n",
    "    graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "    for chunk in graph.stream(\n",
    "        initial_state,\n",
    "        config=config,\n",
    "        stream_mode=[\"values\"]\n",
    "    ):\n",
    "        print(chunk)\n",
    "        if chunk[0] == \"values\":\n",
    "            result_1 = chunk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_1[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92894302",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Nice, I love HeGaalah Open Ear Bone Conduction Headphones and jumper Laptop, 16 Inch FHD IPS Display. Can you add 2 of each to my cart?\"}],\n",
    "    \"user_id\": \"123456\",\n",
    "    \"cart_id\": \"abcdefg\",\n",
    "    \"product_qa_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": product_qa_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"shopping_cart_agent\": {\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": False,\n",
    "        \"available_tools\": shopping_cart_agent_tool_descriptions,\n",
    "        \"tool_calls\": []\n",
    "    }\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": \"test111111111111111111114\"}}\n",
    "\n",
    "with PostgresSaver.from_conn_string(\"postgresql://langgraph_user:langgraph_password@localhost:5433/langgraph_db\") as checkpointer:\n",
    "\n",
    "    graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "    for chunk in graph.stream(\n",
    "        initial_state,\n",
    "        config=config,\n",
    "        stream_mode=[\"values\"]\n",
    "    ):\n",
    "        print(chunk)\n",
    "        if chunk[0] == \"values\":\n",
    "            result_2 = chunk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373851b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a1da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
